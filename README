This is a prototype of a Thundering-Herd prevention for memcached.
As most such systems, it doesn't play nice with incompatible modes
of access to the same keys, but that's not so much surprise, one
would hope.

Specifically, the algorithm attempts to provide means of dealing
with two kinds of situations. Most similar systems appear to be
targeted at the first and more common situation only:

1) A hot cached value expires. Between the point in time when it
   expired and the time when the first user has recomputed the
   value and successfully filled the cache, all users of the cache
   will, in a naive cache client implementation, attempt to
   recalculate the value to store in the cache. This can bring down
   back-end systems that are not designed to handle the load of
   all front-ends that rely on the cache[1].

2) A normal web environment has rather friendly, randomized access
   patterns. But if your cache has a number of near-synchronized
   clients that all attempt to access a new cache key in unison
   (such as when a second or a minute roll around), then some of the
   mechanisms that can help in situation 1 break down.

A very effective approach to deal with most causes of situation 1)
is described in [2]. In a nutshell, it's a trade-off in that we
accept that for a small amount time, we will serve data from a stale
cache. This small amount of time is the minimum of either: the time it
takes for a single process to regenerate a fresh cache value or
a configured threshold. This has the effect that when a cache entry
expired, the first to request the cache entry will start reprocessing
and all subsequent accesses until the reprocessing is done will use
the old, slightly outdated cached data.

That approach does not handle situation 2), in which many clients
attempt to access a cache entry that didn't previously exist. For this
situation, there is a configurable back-off time, or a custom hook
interface to intercept such cases and handle them with custom logic.

[1] I am of the firm (and learned) opinion that when you're in such
    a situation, your cache is no longer strictly a cache and memcached
    is no longer the appropriate technology to use.
[2] See https://github.com/ericflo/django-newcache
    and https://bitbucket.org/zzzeek/dogpile.cache/ for examples of
    prior art.
